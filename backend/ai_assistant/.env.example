# =============================================================================
# AI Assistant Configuration (for Python backend)
# =============================================================================

# Active AI Provider: "gemini" or "groq"
ACTIVE_PROVIDER=gemini

# Optional: Override the default model for the active provider
# Leave empty to use provider defaults
# Gemini models: gemini-1.5-flash, gemini-1.5-pro, gemini-2.0-flash
# Groq models: llama-3.3-70b-versatile, llama-3.1-8b-instant, meta-llama/llama-4-scout-17b-16e-instruct
ACTIVE_MODEL=

# Gemini API Key (Get from: https://aistudio.google.com/apikey)
# Note: GOOGLE_API_KEY is already in main .env, this section is for reference
# GOOGLE_API_KEY=your_gemini_api_key_here

# Groq API Key (Get from: https://console.groq.com/keys)  
GROQ_API_KEY=your_groq_api_key_here

# Flask server settings (AI Assistant runs on 5050 to avoid conflict with Node.js on 5000)
FLASK_HOST=127.0.0.1
FLASK_PORT=5050
FLASK_DEBUG=True

# Enable demo mode (returns mock responses without API calls)
DEMO_MODE=False
